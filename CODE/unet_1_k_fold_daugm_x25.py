# -*- coding: utf-8 -*-
"""unet_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uc0obFicJRgnn5jGvvu4Mq361goDKjQ6
"""

import os
from reprlib import aRepr
# for reading and processing images
import imageio
import matplotlib.pyplot as plt
import numpy as np # for using np arrays
from numpy import asarray
import cv2
import tensorflow as tf
from tensorflow.keras import layers
import os

"""Visualize/explore the dataset of images and masks"""

np.random.seed(42) 



def show_image_mask(img_view,mask_view):
  fig, arr = plt.subplots(1, 2, figsize=(5, 5))
  arr[0].imshow(img_view)
  arr[0].set_title('Image ' )
  arr[1].imshow(mask_view)
  arr[1].set_title('Masked Image ')


"""  LOAD AND SCALE DATA  """

Xx = np.load("X.npy")
yy = np.load("Y.npy")


def scale_dataset(i_h,i_w):
  m,a,b=Xx.shape
  X = np.zeros((m,i_h,i_w), dtype=np.float32)
  y = np.zeros((m,i_h,i_w), dtype=np.float32)

  i=0
  for img in Xx:
    scaled = cv2.resize(img,dsize=(i_w,i_h), interpolation=cv2.INTER_LINEAR) 
    X[i] =scaled/255
    i=i+1
  i=0
  for mask in yy:
    scaled = cv2.resize(mask,dsize=(i_w,i_h), interpolation=cv2.INTER_LINEAR) 
    y[i] =scaled/255
    i=i+1

  return X,y

#X,y = scale_dataset(400,256)
Xs,ys = scale_dataset(256,400)


print('X and y ready scaled')

## ------------------------------------------------------------------------------------------------

def gen_unif_dist(a,b,n):
  return np.random.uniform(a,b,n)

"""#   DATA AUGMENTATION ON THE TRAINING DATASET"""
def augment_image(img,i_w,i_h):
  
  im0 =horizontal_mirror(img)

  factor_hz = gen_unif_dist(-10,10,10)
  im1 =scale_horizontal(img,factor_hz[0],i_w,i_h)
  im2 =scale_horizontal(img,factor_hz[1],i_w,i_h)
  im3 =scale_horizontal(img,factor_hz[2],i_w,i_h)
  im4 =scale_horizontal(img,factor_hz[3],i_w,i_h)
  im5 =scale_horizontal(img,factor_hz[4],i_w,i_h)
  im6 =scale_horizontal(img,factor_hz[5],i_w,i_h)
  im7 =scale_horizontal(img,factor_hz[6],i_w,i_h)
  im8 =scale_horizontal(img,factor_hz[7],i_w,i_h)
  im9 =scale_horizontal(img,factor_hz[8],i_w,i_h)
  im10 =scale_horizontal(img,factor_hz[9],i_w,i_h)

  factor_vrt = gen_unif_dist(-15,15,10)
  im11 =scale_vertical(img,factor_vrt[0],i_w,i_h)
  im12 =scale_vertical(img,factor_vrt[1],i_w,i_h)
  im13 =scale_vertical(img,factor_vrt[2],i_w,i_h)
  im14 =scale_vertical(img,factor_vrt[3],i_w,i_h)
  im15 =scale_vertical(img,factor_vrt[4],i_w,i_h)
  im16 =scale_vertical(img,factor_vrt[5],i_w,i_h)
  im17 =scale_vertical(img,factor_vrt[6],i_w,i_h)
  im18 =scale_vertical(img,factor_vrt[7],i_w,i_h)
  im19 =scale_vertical(img,factor_vrt[8],i_w,i_h)
  im20 =scale_vertical(img,factor_vrt[9],i_w,i_h)
  
  im21 = change_brightness(img,0.5)
  im22 = change_brightness(img,0.6)
  im23 = change_brightness(img,0.7)
  im24 = change_brightness(img,0.8)

  return [im0,im1,im2,im3,im4,im5,im6,im7,im8,im9,im10,im11,im12,im13,im14,im15,im16,im17,im18,im19,im20,im21,im22,im23,im24]

def scale_vertical(img,factor,i_w,i_h):
  new_height = int(img.shape[0]*(1+factor/100))
  dim_size = (img.shape[1],new_height)
  vertical_img2 = cv2.resize(img, dim_size, interpolation=cv2.INTER_LINEAR)

  vertical_img=cv2.resize(vertical_img2, dsize=(i_w,i_h), interpolation=cv2.INTER_LINEAR) 

  return vertical_img

# horizontal scaling
def scale_horizontal(img,factor,i_w,i_h):
  new_width = int(img.shape[1]*(1+factor/100))
  dim_size = (new_width,img.shape[0])
  horizon_img2 = cv2.resize(img, dim_size, interpolation=cv2.INTER_LINEAR)

  horizon_img=cv2.resize(horizon_img2, dsize=(i_w,i_h), interpolation=cv2.INTER_LINEAR) 
  return horizon_img

def horizontal_mirror(img):
  return np.fliplr(img)

def change_brightness(image,gain):
   new_image = tf.image.adjust_brightness(image, gain)
   return new_image.numpy()


def image_augment(na,i_h,i_w,X,y):
  # Pull the relevant dimensions for image and mask
  m,a,b = X.shape  # pull height, width, and channels of image

  # Define X and Y as number of images along with shape of one image
  Xa = np.zeros((m*na,i_h,i_w), dtype=np.float32)
  ya = np.zeros((m*na,i_h,i_w), dtype=np.float32)

  i = 0 
  for single_img in X:
    imgs =augment_image(single_img,i_w,i_h)
    #im0,im1,im2,im3,im4,im5,im6,im7,im8,im9,im10,im11,im12,im13,im14,im15,im16,im17,im18,im19,im20,im21,im22,im23,im24 = 

    for k in range(25):
      Xa[i]= imgs[k]
      i+=1
  
  i = 0  
  for single_mask in y:
    masks= augment_image(single_mask,i_w,i_h)

    for k in range(25):
      ya[i]= masks[k]
      i+=1
   
    
    #im1,im2,im3,im4,im5,im6,im7 = augment_image(single_mask,i_w,i_h)

    # i+=1
    # ya[i]=cv2.resize(im2,dsize=(i_w,i_h), interpolation=cv2.INTER_LINEAR) 
    # i+=1 
    # ya[i]=cv2.resize(im3, dsize=(i_w,i_h), interpolation=cv2.INTER_LINEAR)  
    # i+=1
    # ya[i]=cv2.resize(im4,dsize=(i_w,i_h), interpolation=cv2.INTER_LINEAR)  
    # i+=1 
    # ya[i]=im5
    # i+=1
    # ya[i]=im6
    # i+=1
    # ya[i]=im7
    # i+=1   

       
  return Xa,ya



# Start from here with data loaded



import time
# for bulding and running deep learning model
from tensorflow import keras
from tensorflow.keras import layers

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import Input
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.layers import Dropout 
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import Conv2DTranspose
from tensorflow.keras.layers import concatenate
from tensorflow.keras.losses import binary_crossentropy
from tensorflow.keras.layers import UpSampling2D
import pandas as pd
from tensorflow import keras
from keras import backend as K
#---------------------------------

def unet_1(pretrained_weights = None, input_shape = (400,256)):
    inputs = tf.keras.Input(input_shape)
    #inputs2 =  tf.keras.layers.Rescaling(1.0 / 255, offset=0.0)(inputs)
    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)
    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)
    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)
    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)
    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)
    drop4 = Dropout(0.5)(conv4)
    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)
    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)
    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)
    drop5 = Dropout(0.5)(conv5)
    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))
    merge6 = concatenate([drop4,up6], axis = 3)
    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)
    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)
    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))
    merge7 = concatenate([conv3,up7], axis = 3)
    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)
    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)
    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))
    merge8 = concatenate([conv2,up8], axis = 3)
    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)
    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)
    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))
    merge9 = concatenate([conv1,up9], axis = 3)
    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)
    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)
    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)
    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)
    model = Model(inputs = inputs, outputs = conv10)


    #model.summary()
    if(pretrained_weights):
        model.load_weights(pretrained_weights)
    return model


def dice_coef2p0(y_true, y_pred, smooth=0):
    #
    #Dice = (2*|X & Y|)/ (|X|+ |Y|)
    #     =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))
    #ref: https://arxiv.org/pdf/1606.04797v1.pdf
    #
    intersection = K.sum(K.abs(y_true * y_pred))
    return (2. * intersection + smooth) / (K.sum(K.abs(y_true)) + K.sum(K.abs(y_pred)) + smooth)
def dice_coef_loss(y_true, y_pred):
    return 1-dice_coef2p0(y_true, y_pred)

model = unet_1(pretrained_weights = None, input_shape = (256, 400,1))
#model = unet_1(pretrained_weights = None, input_shape = (400, 256,1))
#model.summary()


#--------------------------------------------------------------------
# Use k-fold validation. The size of the full dataset 
# (without augmentation is 529 images-masks)
#--------------------------------------------------------------------
#--------------------------------------------------------------------
from sklearn.model_selection import KFold, train_test_split
"""SPLIT DATA INTO TRAIN-VALIDATION-TEST"""


#Divide dataset in train+val ---- test
x_train_val, x_test, y_train_val, y_test = train_test_split(Xs,ys, test_size=0.1, random_state=42,shuffle=False)
#Leave 10% of the data to then test the model with new data, unseen for the model
#x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2

print("shape of x_train_val")
print(x_train_val.shape)

       
kf = KFold(n_splits=5,random_state=42, shuffle=True)
#kf.get_n_splits(X)

k_iter = 0


num_epochs = 10

nsamples, nx, ny = x_train_val.shape
d2_x_train_val = x_train_val.reshape((nsamples,nx*ny))

nsamples, nx, ny = y_train_val.shape
d2_y_train_val = y_train_val.reshape((nsamples,nx*ny))


#------------------------------------------------
#         K-FOLD TRAIN-VAL PROCEDURE.
#------------------------------------------------
for train_index, val_index in kf.split(d2_x_train_val, d2_y_train_val):

  k_iter+=1
  print(' K = '+str(k_iter))
  # COMPILE NEW MODEL
  model.compile(optimizer = keras.optimizers.Adam(learning_rate=1e-4),
              loss=dice_coef_loss,
              metrics = ['accuracy'])
              
  callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5) #early stopping
  x_train_fold = x_train_val[train_index]
  print("shape of x_train_fold")
  print(x_train_fold.shape)

	# There can be other callbacks, but just showing one because it involves the model name
	# This saves the best model
	# AUGMENT DATA FOR TRAINING
  x_fold = x_train_val[train_index]
  y_fold = y_train_val[train_index]
  na = 25
  Xa,ya = image_augment(na,256, 400,x_fold,y_fold)


  X_augm = np.concatenate((x_fold,Xa))
  y_augm = np.concatenate((y_fold,ya))

	# AUGMENT DATA FOR VALIDATION
  x_fold_val = x_train_val[val_index]
  y_fold_val = y_train_val[val_index]
  na =25
  Xa_val,ya_val = image_augment(na,256, 400,x_fold_val,y_fold_val)
  X_augm_val = np.concatenate((x_fold_val,Xa_val))
  y_augm_val = np.concatenate((y_fold_val,ya_val))

  history = model.fit(X_augm,y_augm,
        	    epochs=num_epochs,
                batch_size=10,
			    callbacks=[callback],
			    validation_data=(X_augm_val,y_augm_val))
	


  # list all data in history
  print(history.history.keys())
  # summarize history for accuracy
  plt.plot(history.history['accuracy'])
  plt.plot(history.history['val_accuracy'])
  plt.title('model accuracy')
  plt.ylabel('accuracy')
  plt.xlabel('epoch')
  plt.legend(['train', 'val'], loc='upper left')
  #plt.show()
  plt.savefig('./results_unet1_aug/'+'acc_k_'+str(k_iter)+'.png',format='png')
  plt.close()

  # summarize history for loss
  plt.plot(history.history['loss'])
  plt.plot(history.history['val_loss'])
  plt.title('model loss')
  plt.ylabel('loss')
  plt.xlabel('epoch')
  plt.legend(['train', 'val'], loc='upper left')
  plt.savefig('./results_unet1_aug/'+'loss_k_'+str(k_iter)+'.png',format='png')
  plt.close()


  results = model.evaluate(X_augm_val,y_augm_val)
  results = dict(zip(model.metrics_names,results))

  # PREDICT ON *VALIDATION* DATA
  yp_val = model.predict(X_augm_val)
 
  #save_name = "augm_y_pred_xval_k_"+str(k_iter)+".npy"
  #np.save(save_name, yp_val)

  loss, accuracy = model.evaluate(x_train_val[val_index],y_train_val[val_index])
  print("RESTULS WITH VALIDATION DATA")
  print("Loss: ", loss)
  print("Accuracy: ", accuracy)
  print("-------------------------------------------------------")


  loss, accuracy = model.evaluate(x_test,y_test)
  print("RESTULS WITH TEST DATA")
  print("Loss: ", loss)
  print("Accuracy: ", accuracy)
  print("-------------------------------------------------------")
  
  #save each k-model
  # Calling `save('my_model')` creates a SavedModel folder `my_model`.
  model_name = 'augm_model_'+str(k_iter)
  model.save(model_name)
  
  # PREDICT ON *TEST* DATA. This dataset has NOT been used to train the model
  yp = model.predict(x_test)

  save_name = "augm_y_pred_xtest_k_"+str(k_iter)+".npy"
  np.save(save_name, yp)



  # if k_iter == 2:
  #   n_images_save = 8*4
  #   for i in range(n_images_save):
  #     plt.figure(figsize=(20,10))
  #     plt.subplot(1,3,1)
  #     plt.imshow(x_test[i])
  #     plt.title('Input')
  #     plt.subplot(1,3,2)
  #     plt.imshow(y_test[i].reshape(y_test[i].shape[0],y_test[i].shape[1]))
  #     plt.title('Ground Truth')
  #     plt.subplot(1,3,3)
  #     plt.imshow(yp[i].reshape(yp[i].shape[0],yp[i].shape[1]))
  #     plt.title('Prediction')
  #     plt.savefig('./results_unet1_aug/'+str(i)+'.png',format='png')
  #     plt.close()















